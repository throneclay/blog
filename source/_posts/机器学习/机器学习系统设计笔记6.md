title: 机器学习系统设计笔记6--回归
date: 2015-10-19 21:47:52
categories: 机器学习
tags: 机器学习
plink: mldesgin7
mathjax: true
---

最近看完了 Willi Richert的《机器学习系统设计》。书虽然有点薄但也比较全，内容感觉有点偏文本处理，里面介绍了一些文本处理的方法和工具。综合起来看作为机器学习入门还是挺不错的，这里就简单记一下我做的笔记，方便回顾。书中的代码可以通过它说到的[网站](https://www.packtpub.com/books/content/support/11704)下载，这里是第6部分笔记。

## 第七，八章 回归

回归问题对于一些预测类的问题很有效，目前也有很多比较先进的方法，属于一个重要的领域。

### Ordinary Least Squares [普通最小二乘法](https://zh.wikipedia.org/zh-cn/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95)

从一个简单的例子看一下这个方法，预测波士顿房价，数据在sklearn中已经自带了,我们使用numpy的包来计算回归曲线

```
>>> from sklearn.datasets import load_boston
>>> boston = load_boston()
>>> import numpy as np
>>> x = boston.data[:,5]
>>> x = np.array([[v] for v in x]) ## 这个用法我之前并没有看到过，意思就是把x中的数据按照取出来，放到前面那个序列中拼起来
>>> y = boston.target
>>> slop,_,_,_ = np.linalg.lstsq(x,y)
```

由于对数据拟合的过好，会出现很多偏差，我们一般采用在前面的式子中加入偏移量，如加1:

```
>>> x = boston.data[:,5]
>>> x = np.array([[v,1] for v in x]) ## 多加一列就是加入偏移量了？！
```

sklearn中也实现了线性回归，而且sklearn使用了更方便的接口来添加偏移量：

```
>>> from sklearn.linear_model import LinearRegression
>>> lr = LinearRegression(fit_intercept=True) ##加入偏移项
>>> lr.fit(x,y)
>>> p = map(lr.predict, x)
>>> e = p-y ## 误差
>>> total_error = np.sum(e*e) ## 平方和
>>> rmse_train = np.sqrt(total_error/len(p)) ##均方误差
```

### 惩罚式回归

有两种类型的惩罚經常用语回归：L1惩罚和L2惩罚。L1惩罚的意思是说，我们通过系数的绝对值之和对回归进行惩罚，而L2惩罚则通过平方和来惩罚。惩罚式回归是偏差方差折中的一个例子，在使用惩罚项时，由于增加了偏差，我们会得到一个训练效果差一些的拟合。但另一方面，我们降低了方差，从而更易于避免过拟合，因此整体效果可以范化的更好。

L1惩罚模型通常叫做Lasso法，L2惩罚通常叫做岭回归(Ridge regression)。两者的结合就得到了弹性网(Elastic net)模型。

对于OLS来说，他的优化如下：

$$\vec{b}=argmin_{\vec{b}}(y-X\vec{b})^2$$

使用L1惩罚项的时候，我们会优化下面这个式子：

$$\vec{b}=argmin_{\vec{b}}(y-X\vec{b})^2+\lambda \sum \_i|b_i|$$

使用L2惩罚项的时候，我们会优化下面这个式子：

$$\vec{b}=argmin_{\vec{b}}(y-X\vec{b})^2+\lambda \sum \_i b\_i^2$$

他们的区别比较小，但Lasso有一个额外的性质，就是他会让更多的系数为0，也就是说，最终的模型甚至不会使用一些输入特征，模型是稀疏的，这通常是一个非常好的性质，因为模型把特征选择和回归在同一个步骤中都实现了。

### $P$大于$N$的情形

$P$是输入的特征个数，$N$是样本数，对于$P$大于$N$的回归问题，有可能会在训练数据中得到一个完美的拟合，然而这时候的范化能力可能非常差，可以通过提高惩罚参数来解决这个问题，但惩罚参数设的过高也可能导致欠饱和，因此我们需要对样本进行两层的交叉验证，外层用来评估范化能力，内层用来获得好的参数。

sklearn中已经内置了这件事情，他们叫做LassoCV,RidgeCV,和ElasticNetCV，他们都内部参数封装了交叉验证检查。

### 推荐系统

对于一些像NetFlix这样的网站，需要判断用户的口味来进行推荐，这种问题往往不属于分类问题，使用回归方法能够较好的解决这类问题。对于推荐电影来说，我们有两种思路来进行推荐，构建电影特定模型和用户特定模型，前者表示这个电影适合哪些用户，后者表示这个用户适合哪些电影。我们使用后者来进行建模，针对每个用户，我们把电影评分当做目标变量。而输入数据就是其他用户的打分。对于那些与我们的目标用户观影喜好较为相似的用户，模型会赋予他们的电影评分较高的权重分值；对于那些与我们的目标用户观影喜好完全相反的用户，模型会赋予他们的电影评分一个负值。

我们或者可以先对用户的相近程度对用户进行排序，对电影数据进行评分的时候从用户的近邻查找评分，找到的第一个分数当作结果输出。

这里我们有两个弱分类器，能够比随即猜测表现的稍好，在这种情况下，我们可以使用集成学习。这是一种通用的技术，并不仅仅适用于回归问题，我们学习出一组分类器的结果，再由后续的分类器对这些结果进行综合，得出最终的结果。集成学习中，若分类器的种类越多，差异越大，往往效果也越好。

### 购物篮分析及预测

购物篮分析是另一种推荐系统，这里并没有评分，而是要么购买要么没有购买，往往这种推荐系统的需求要更多一些。网上虽然有一些购物篮分析算法的开源实现，但并没有一个能很好的整合在scikit-learn或者其他程序库中。推荐系统有一个经典算法那就是Apriori算法，虽然提出的时间比较长，但效果还是不错的。
