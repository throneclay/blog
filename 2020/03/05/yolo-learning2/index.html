<!DOCTYPE html><html lang="[&quot;zh-CN&quot;,&quot;zh-TW&quot;,&quot;en&quot;,&quot;de-DE&quot;,&quot;es-ES&quot;,&quot;fr-FR&quot;,&quot;ko&quot;,&quot;default&quot;]"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>yolov3实战指南--训练自有数据集并完成TensorRT推理实践 | 流水的账</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/rss+xml" href="/rss2.xml"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 6.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">yolov3实战指南--训练自有数据集并完成TensorRT推理实践</h1><a id="logo" href="/.">流水的账</a><p class="description">戒骄戒躁，脚踏实地。</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/rss2.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">yolov3实战指南--训练自有数据集并完成TensorRT推理实践</h1><div class="post-meta">2020-03-05<span> | </span><span class="category"><a href="/categories/deepLearning/">深度学习</a></span></div><a class="disqus-comment-count" href="/2020/03/05/yolo-learning2/#vcomment"><span class="valine-comment-count" data-xid="/2020/03/05/yolo-learning2/"></span><span> 条评论</span></a><div class="post-content"><p>就在写这篇文章的时候，yolo作者Joseph Redmon宣布停止CV研究，很可能yolov3将成为yolo系列的终局。想到这个感觉还是要好好写一下yolo啊。本来只想写一篇来介绍一下yolov3并记录下我是如何用到自己数据集上，写完后发现篇幅很长，遂拆成两部分。</p>
<p>此篇为目的是要记录如何使用自己的数据集训练yolov3模型，并<strong>最终得到能够上线的检测模型</strong>。这里训练不是学术目的，而是面向生产环境。理论篇见<a href="http://blog.throneclay.top/2020/02/19/yolo-learning/">http://blog.throneclay.top/2020/02/19/yolo-learning/</a>。</p>
<h2 id="darknet框架"><a href="#darknet框架" class="headerlink" title="darknet框架"></a>darknet框架</h2><p>直接使用原版代码也可以，但我这里使用的是并不是原版的darknet，而是一个更容易阅读的fork版本，<a target="_blank" rel="noopener" href="https://github.com/AlexeyAB/darknet">https://github.com/AlexeyAB/darknet</a>，此版本兼容原版darkent，并对于darknet的代码结构进行了升级，对于上手非常友好。</p>
<p>编译是非常容易的，需要装好cuda和cudnn，我用了conda来创建编译环境。（你没看错，是conda，conda同样能够管理常用的c++环境）。用conda可以轻松的在不同cmake版本中间穿梭，非常方便。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">conda</span> create --name darknet cmake=<span class="number">3</span>.<span class="number">8</span>.<span class="number">2</span></span><br><span class="line"><span class="attribute">conda</span> activate darknet</span><br><span class="line"><span class="attribute">conda</span> install opencv</span><br></pre></td></tr></table></figure>

<p>完成后，这个环境下的cmake版本就应该没问题了。进入repo根目录，进行编译</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="keyword">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line"><span class="keyword">make</span></span><br><span class="line"><span class="keyword">make</span> install</span><br></pre></td></tr></table></figure>

<p>编译没问题后，在根目录下会出现darknet，后面主要就是用它来执行训练等任务。</p>
<h2 id="数据准备及config目录结构"><a href="#数据准备及config目录结构" class="headerlink" title="数据准备及config目录结构"></a>数据准备及config目录结构</h2><p>在这里其实有三组config，分散在两个文件夹中，分别是记录训练数据的config，扩展名为data。记录训练类别和名称的config，扩展名为names和网络的config，扩展名为cfg，内容比较直白，接下来分步骤说一下全流程。这里假设你的数据集为obj，网络名称也就叫做yolov3-obj了。</p>
<h3 id="1-创建网络cfg"><a href="#1-创建网络cfg" class="headerlink" title="1. 创建网络cfg"></a>1. 创建网络cfg</h3><p>复制一下cfg&#x2F;yolov3.cfg到cfg&#x2F;yolov3-obj.cfg，修改文件里的内容如下</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">batch</span>=<span class="number">1</span>              ==&gt;  batch=<span class="number">64</span></span><br><span class="line"><span class="attribute">subdivisions</span>=<span class="number">1</span>       ==&gt;  subdivisions=<span class="number">16</span></span><br><span class="line"><span class="attribute">max_batches</span> = <span class="number">500200</span> ==&gt;  max_batches = (类别数 x <span class="number">2000</span>，如一共<span class="number">3</span>类就是<span class="number">6000</span>)</span><br><span class="line"><span class="attribute">steps</span>=<span class="number">400000</span>,<span class="number">450000</span>  ==&gt;  steps=(上面max_batches的<span class="number">80</span>%,, <span class="number">90</span>%，如<span class="number">4800</span>,<span class="number">5400</span>)</span><br><span class="line"><span class="attribute">width</span>=<span class="number">416</span>            ==&gt;  width=(网络输入图像大小，<span class="number">32</span>的倍数，可选，不一定要修改这个参数，内部会自动resize)</span><br><span class="line"><span class="attribute">height</span>=<span class="number">416</span>           ==&gt;  height=(网络输入图像大小，<span class="number">32</span>的倍数，可选，不一定要修改这个参数，内部会自动resize)</span><br><span class="line"><span class="attribute">classes</span>=<span class="number">80</span>           ==&gt;  classes=(类别数量， 即前面max_batches乘的类别数量)</span><br><span class="line"><span class="attribute">filters</span>=<span class="number">255</span>          ==&gt;  filters=(classes + <span class="number">5</span>) x <span class="number">3</span> 都是在[convolutional]，共有<span class="number">3</span>处，需要都修改一下，这个filter是在[yolo] layer的上一层。</span><br></pre></td></tr></table></figure>

<h3 id="2-创建obj-names"><a href="#2-创建obj-names" class="headerlink" title="2. 创建obj.names"></a>2. 创建obj.names</h3><p>创建data&#x2F;obj.names文件，一行有且只有一个对应的object name。最后输出也会按照这个顺序。</p>
<h3 id="3-创建obj-data文件"><a href="#3-创建obj-data文件" class="headerlink" title="3. 创建obj.data文件"></a>3. 创建obj.data文件</h3><p>创建cfg&#x2F;obj.data，内容如下</p>
<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">classes</span><span class="operator">=</span> <span class="number">3</span></span><br><span class="line"><span class="attribute">train</span>  <span class="operator">=</span> train/train.txt</span><br><span class="line"><span class="attribute">valid</span>  <span class="operator">=</span> train/test.txt</span><br><span class="line"><span class="attribute">names</span> <span class="operator">=</span> data/obj.names</span><br><span class="line"><span class="attribute">backup</span> <span class="operator">=</span> train/backup/</span><br></pre></td></tr></table></figure>

<p>解释一下，classes是上面提到的类别数，train指的训练数据的list，后面第6步会再说，位置放在darknet下新建一个train文件夹下，或者你可以修改其他名字，valid就是验证用的list，names指第2步创建的obj.names，backup是darknet存放训练产生的wegiths的位置，先把位置放到train&#x2F;backup中，这里就需要提前把这里用到的文件夹创建出来</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> train</span><br><span class="line"><span class="built_in">mkdir</span> train/backup</span><br></pre></td></tr></table></figure>

<h3 id="4-准备训练用的图片文件"><a href="#4-准备训练用的图片文件" class="headerlink" title="4. 准备训练用的图片文件"></a>4. 准备训练用的图片文件</h3><p>准备下要训练的图片，假设放到&#x2F;home&#x2F;data&#x2F;train_jpg文件夹下，我用的jpg文件的格式，其他格式没有测试过。</p>
<h3 id="5-准备label文件"><a href="#5-准备label文件" class="headerlink" title="5. 准备label文件"></a>5. 准备label文件</h3><p>继续沿用上面的设置，训练图片位于&#x2F;home&#x2F;data&#x2F;train_jpg下，那么label文件就要放到&#x2F;home&#x2F;data&#x2F;labels文件夹下。有多少训练用的图片就要有对应的label文件，名字和train_jpg下的图片一样，扩展名为txt，举个例子如果你有一张训练图片&#x2F;home&#x2F;data&#x2F;train_jpg&#x2F;0001.jpg就需要一个label在&#x2F;home&#x2F;data&#x2F;labels&#x2F;0001.txt，文件的格式如下：</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;object-<span class="keyword">class</span>&gt; &lt;<span class="symbol">reg_x_center</span>&gt; &lt;<span class="symbol">reg_y_center</span>&gt; &lt;<span class="symbol">reg_width</span>&gt; &lt;<span class="symbol">reg_height</span>&gt;</span><br></pre></td></tr></table></figure>

<p>举个例子，内容需要是像下面这种的东西：</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">0 </span><span class="number">0.003852</span> <span class="number">0.928161</span> <span class="number">0.007704</span> <span class="number">0.143678</span></span><br><span class="line"><span class="symbol">1 </span><span class="number">0.537365</span> <span class="number">0.370690</span> <span class="number">0.008475</span> <span class="number">0.201149</span></span><br><span class="line"><span class="symbol">1 </span><span class="number">0.771957</span> <span class="number">0.103448</span> <span class="number">0.009245</span> <span class="number">0.206897</span></span><br><span class="line"><span class="symbol">1 </span><span class="number">0.857858</span> <span class="number">0.100575</span> <span class="number">0.008475</span> <span class="number">0.201149</span></span><br><span class="line"><span class="symbol">1 </span><span class="number">0.994992</span> <span class="number">0.522989</span> <span class="number">0.008475</span> <span class="number">0.195402</span></span><br><span class="line"><span class="symbol">0 </span><span class="number">0.996533</span> <span class="number">0.787356</span> <span class="number">0.006934</span> <span class="number">0.160920</span></span><br></pre></td></tr></table></figure>

<p><strong>label的设置还是很重要的</strong>，这里解释一下，文件中一行代表一个object，每行有5列，用空格进行分割，第一个数是整数，代表之前names文件中的第几个类别，剩下的4列为回归后的x中心，回归后的y中心，回归后的width和回归后的height。<strong>其回归计算公式如下</strong>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reg_x_center = <span class="tag">&lt;<span class="name">absolute_x_center</span>&gt;</span> / <span class="tag">&lt;<span class="name">image_width</span>&gt;</span></span><br><span class="line">reg_y_center = <span class="tag">&lt;<span class="name">absolute_y_center</span>&gt;</span> / <span class="tag">&lt;<span class="name">image_height</span>&gt;</span></span><br><span class="line">reg_width = <span class="tag">&lt;<span class="name">absolute_width</span>&gt;</span> / <span class="tag">&lt;<span class="name">image_width</span>&gt;</span></span><br><span class="line">reg_height = <span class="tag">&lt;<span class="name">absolute_height</span>&gt;</span> / <span class="tag">&lt;<span class="name">image_height</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>每个值都不会大于1的，如果你有算出大于1的地方就肯定算错啦。</p>
<h3 id="6-准备train-txt"><a href="#6-准备train-txt" class="headerlink" title="6. 准备train.txt"></a>6. 准备train.txt</h3><p>沿用上面的设置，训练图片都位于&#x2F;home&#x2F;data&#x2F;train_jpg下，执行下面命令生成train.txt文件，valid.txt文件同理。valid.txt其实就是用来在训练的时候验证效果的，一般就是从train文件中分出一小部分用于valid。label文件不需要设置，darknet会根据train的文件名，自己去找对应的label文件。</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">find</span> <span class="regexp">/home/</span>data<span class="regexp">/train_jpg/</span> &gt; train/train.txt</span><br><span class="line"><span class="keyword">find</span> <span class="regexp">/home/</span>data<span class="regexp">/valid_jpg/</span> &gt; train/valid.txt</span><br></pre></td></tr></table></figure>

<h3 id="7-下载预训练的weights"><a href="#7-下载预训练的weights" class="headerlink" title="7. 下载预训练的weights"></a>7. 下载预训练的weights</h3><p>为了能够让训练过程更顺畅，我们使用预训练的weights来加强效果，因为我们选用了yolov3.cfg，使用下面这个预训练weights</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https:<span class="regexp">//</span>pjreddie.com<span class="regexp">/media/</span>files/darknet53.conv.<span class="number">74</span></span><br></pre></td></tr></table></figure>

<h3 id="8-开始训练"><a href="#8-开始训练" class="headerlink" title="8. 开始训练"></a>8. 开始训练</h3><p>上面步骤确认没有问题后，执行下面命令，训练就开始了</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./darknet detector train data/obj.data cfg/yolov3-obj.cfg darknet53.conv.74</span><br></pre></td></tr></table></figure>
<p>运行这句命令后，会启动可视化的一个界面，如果你不想要可视化的界面，运行下面这句</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./darknet detector train data/obj.data cfg/yolov3-obj.cfg darknet53.conv.74 -dont_show </span><br></pre></td></tr></table></figure>

<p>训练需要点时间，如果出现nan，只要不是在loss里面不用太担心，如果报错，请检查上面1-7步的内容。</p>
<h2 id="TensorRT推理部分的实现及inference"><a href="#TensorRT推理部分的实现及inference" class="headerlink" title="TensorRT推理部分的实现及inference"></a>TensorRT推理部分的实现及inference</h2><p>这里最后使用了TensorRT的C++部分API，实际上也用了python部分API。经过训练在train&#x2F;backup下已经得到了你要的模型。</p>
<p>这里我们换用另一个项目继续得到TensorRT可用的模型<a target="_blank" rel="noopener" href="https://gitlab.com/aminehy/YOLOv3-Darknet-ONNX-TensorRT">YOLOv3-Darknet-ONNX-TensorRT</a></p>
<p>我使用的是python2.7，虽然已经不更新了，但用python2.7加这个项目已经完全足够了，如果使用python3，可以多阅读下项目的README.md</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">conda</span> create --name yolo_trt python=<span class="number">2</span>.<span class="number">7</span></span><br><span class="line"><span class="attribute">conda</span> activate yolo_trt</span><br><span class="line"><span class="attribute">python2</span> -m pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<p>项目应该就算布好了。接下来我们装一下TensorRT的环境，为了兼容线上的版本，我还是用的TensorRT5，新的TensorRT应该跟这个差不多。到<a target="_blank" rel="noopener" href="https://developer.nvidia.com/tensorrt">https://developer.nvidia.com/tensorrt</a>官网下载TensorRT，为了方便安装和使用，我们还是下载他的tar package。</p>
<p>解压出来在home下的.bashrc文件中增加下面两句话就算安装完成了，我直接放我home下了，需要设置cudnn的LD_LIBRARY_PATH，否则会提示cudnn找不到。如果愿意也可以把TensorRT&#x2F;bin放到PATH里，这里就不放了。</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export CUDNN_ROOT=<span class="regexp">/usr/</span>local/cudnn-<span class="number">7.6</span>.<span class="number">0</span>-cuda10.<span class="number">1</span>_0</span><br><span class="line">export LD_LIBRARY_PATH=<span class="regexp">/home/</span>zhangshuai<span class="regexp">/TensorRT-5.1.2.2/</span>lib:<span class="variable">$CUDNN_ROOT</span>/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>

<p>source一下.bashrc，执行TensorRT-5.1.2.2&#x2F;bin&#x2F;giexec，没问题的话就可以看到giexec的help提示。</p>
<h3 id="安装TensorRT的python环境"><a href="#安装TensorRT的python环境" class="headerlink" title="安装TensorRT的python环境"></a>安装TensorRT的python环境</h3><p>我这里是python2.7的，因此安装2.7对应的TensorRT，先安装两个依赖，然后进python文件夹下安装对应的TensorRT。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">conda</span> activate yolo_trt</span><br><span class="line"><span class="attribute">pip</span> install TensorRT-<span class="number">5.1.2.2</span>/uff/uff-<span class="number">0</span>.<span class="number">6</span>.<span class="number">3</span>-py2.py3-none-any.whl</span><br><span class="line"><span class="attribute">pip</span> install TensorRT-<span class="number">5.1.2.2</span>/graphsurgeon/graphsurgeon-<span class="number">0</span>.<span class="number">4</span>.<span class="number">0</span>-py2.py3-none-any.whl</span><br><span class="line"><span class="attribute">pip</span> install TensorRT-<span class="number">5.1.2.2</span>/python/tensorrt-<span class="number">5.1.2.2</span>-cp27-none-linux_x86_64.whl</span><br></pre></td></tr></table></figure>

<p>安装没问题可以测试一下，不报错说明已经安装成功。</p>
<figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -<span class="keyword">c</span> <span class="string">&quot;import tensorrt&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="onnx模型转换"><a href="#onnx模型转换" class="headerlink" title="onnx模型转换"></a>onnx模型转换</h3><p><a target="_blank" rel="noopener" href="https://gitlab.com/aminehy/YOLOv3-Darknet-ONNX-TensorRT">YOLOv3-Darknet-ONNX-TensorRT</a>这个项目其实写的已经很好了，主要就是两个python：yolov3_to_onnx.py和onnx_to_tensorrt.py，其实我们只用第一个文件就可以转换获得onnx的模型，第二个python能够进一步得到trt的engine，trt的engine不是很好用，对于TensorRT的版本，卡的型号都有绑定，不过可以用第二个文件检查第一步产生的onnx模型是不是对的。</p>
<h4 id="1-yolov3-to-onnx-py转换onnx模型"><a href="#1-yolov3-to-onnx-py转换onnx模型" class="headerlink" title="1. yolov3_to_onnx.py转换onnx模型"></a>1. yolov3_to_onnx.py转换onnx模型</h4><p>把之前backup训练得到的yolov3_all_final.weights放到项目路径下，修改weights_file_path指向你的weights,默认的参数就是416x416对应的参数，在项目路径下创建engine文件夹，在之前创建的yolo_trt下直接运行</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">python</span> yolov3_to_onnx.<span class="keyword">py</span></span><br></pre></td></tr></table></figure>
<p>不出问题的话，engine下就多了一个onnx的模型</p>
<h4 id="2-onnx-to-tensorrt-py"><a href="#2-onnx-to-tensorrt-py" class="headerlink" title="2. onnx_to_tensorrt.py"></a>2. onnx_to_tensorrt.py</h4><p>这个文件可能需要修改一下output_shape，我这里修改了</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output_shapes = [<span class="comment">(1, 255, 19, 19)</span>, <span class="comment">(1, 255, 38, 38)</span>, <span class="comment">(1, 255, 76, 76)</span>]</span><br><span class="line">  ==&gt;  output_shapes = [<span class="comment">(1, 51, 13, 13)</span>, <span class="comment">(1, 51, 26, 26)</span>, <span class="comment">(1, 51, 52, 52)</span>]</span><br></pre></td></tr></table></figure>
<p>其实运行一下根据报错也很容易看到。<br>修改后确认下test文件夹是否存在，你可以放入一些自己的测试图片，运行就能看到模型从load到inference的过程了，results文件夹下会得到这次的一些结果。</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">python</span> onnx_to_tensorrt.<span class="keyword">py</span></span><br></pre></td></tr></table></figure>

<p>至此，全流程算是走了一遍了，但我们的目的是上线C++的项目，所以还要继续。</p>
<h3 id="c-部分实现"><a href="#c-部分实现" class="headerlink" title="c++部分实现"></a>c++部分实现</h3><p>C++部分分为两部分，一部分就是load图像，跑TensorRT的过程，可以参考TensorRT&#x2F;samples&#x2F;trtexec代码。这里就不再多说什么，最后你会获得三组输出，处理的方法都是一样的，这里写了个函数，应该可以帮你理解和处理yolov3的输出。这个函数可以处理一个输出的box结果，最后的结果就是这三组输出的总和。</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__inline__ <span class="type">float</span> <span class="title">sigmoid_f</span><span class="params">(<span class="type">const</span> <span class="type">float</span>&amp; value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1.f</span> / (<span class="number">1.f</span> + <span class="built_in">expf</span>(-value));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">TrafficLightDetector::get_detection_bbox</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    std::vector&lt;std::vector&lt;<span class="type">float</span>&gt; &gt; &amp;bbox, <span class="comment">// the output of this function</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> batch_index,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">float</span>* output_data, <span class="comment">// tensorrt output data on cpu</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> channel, <span class="comment">// output data channel</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> height, <span class="comment">// output data height</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> width, <span class="comment">// output data width</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> image_origin_height, <span class="comment">// image origin height 416</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> image_origin_width, <span class="comment">// image origin width 416</span></span></span></span><br><span class="line"><span class="params"><span class="function">    std::vector&lt;std::vector&lt;<span class="type">int</span>&gt; &gt; anchor_mask, <span class="comment">// &#123;&#123;6, 7, 8&#125;, &#123;3, 4, 5&#125;, &#123;0, 1, 2&#125;&#125;;</span></span></span></span><br><span class="line"><span class="params"><span class="function">    std::vector&lt;std::vector&lt;<span class="type">float</span>&gt; &gt; anchors, <span class="comment">// &#123;&#123;10, 13&#125;, &#123;16, 30&#125;, &#123;33, 23&#125;, </span></span></span></span><br><span class="line"><span class="params"><span class="function">                                              <span class="comment">// &#123;30, 61&#125;, &#123;62, 45&#125;, &#123;59, 119&#125;,</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                              <span class="comment">// &#123;116, 90&#125;, &#123;156, 198&#125;, &#123;373, 326&#125;&#125;;</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> output_index, <span class="comment">// anchor_mask index</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">float</span> obj_thresh = <span class="number">0.3f</span> <span class="comment">// score threshold</span></span></span></span><br><span class="line"><span class="params"><span class="function">    )</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> tensor_idx = output_index;</span><br><span class="line">  output_data += batch_index * channel * height * width;</span><br><span class="line">  <span class="type">int</span> size = height * width;</span><br><span class="line">  <span class="type">int</span> stride = height * width;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> max_anchor = <span class="number">-1</span>;</span><br><span class="line">    <span class="type">int</span> max_index = <span class="number">-1</span>;</span><br><span class="line">    <span class="type">float</span> max_confidence = <span class="number">-1.f</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">unsigned</span> <span class="type">int</span> anchor_i = <span class="number">0</span>; </span><br><span class="line">        anchor_i &lt; anchor_mask[tensor_idx].<span class="built_in">size</span>(); ++anchor_i) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="type">int</span> max_index_ = <span class="number">-1</span>;</span><br><span class="line">      <span class="type">float</span> max_confidence_ = <span class="number">-1.f</span>;</span><br><span class="line"></span><br><span class="line">      <span class="type">float</span> confidence = <span class="built_in">sigmoid_f</span>(output_data[</span><br><span class="line">          anchor_i * (<span class="number">5</span> + classes) * stride + <span class="number">4</span> * stride + i]);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> c = <span class="number">0</span>; c &lt; classes; ++c) &#123;</span><br><span class="line">        <span class="type">float</span> bbox_confidence = confidence * <span class="built_in">sigmoid_f</span>(output_data[</span><br><span class="line">            anchor_i * (<span class="number">5</span> + classes) * stride + (<span class="number">5</span> + c) * stride + i]);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (bbox_confidence &gt; obj_thresh) &#123;</span><br><span class="line">          <span class="keyword">if</span> (bbox_confidence &gt; max_confidence_) &#123;</span><br><span class="line">            max_confidence_ = bbox_confidence;</span><br><span class="line">            max_index_ = c;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (max_confidence_ &gt; max_confidence) &#123;</span><br><span class="line">        max_confidence = max_confidence_;</span><br><span class="line">        max_index = max_index_;</span><br><span class="line">        max_anchor = anchor_i;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// found bbox</span></span><br><span class="line">    <span class="keyword">if</span> (max_index != <span class="number">-1</span>) &#123;</span><br><span class="line">      <span class="type">float</span> grid_x = (<span class="type">float</span>)(i % width);</span><br><span class="line">      <span class="type">float</span> grid_y = (<span class="type">float</span>)(i / width);</span><br><span class="line">      std::cout &lt;&lt; <span class="string">&quot;max_index = &quot;</span> &lt;&lt; max_index</span><br><span class="line">        &lt;&lt; <span class="string">&quot; max_anchor = &quot;</span> &lt;&lt; max_anchor</span><br><span class="line">        &lt;&lt; <span class="string">&quot; i = &quot;</span> &lt;&lt; i</span><br><span class="line">        &lt;&lt; <span class="string">&quot; grid_x = &quot;</span> &lt;&lt; grid_x &lt;&lt;</span><br><span class="line">        <span class="string">&quot; grid_y = &quot;</span> &lt;&lt; grid_y &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// compute bbox information</span></span><br><span class="line">      <span class="type">float</span> box_x = <span class="built_in">sigmoid_f</span>(output_data[</span><br><span class="line">          max_anchor * (<span class="number">5</span> + classes) * stride + i]);</span><br><span class="line">      <span class="type">float</span> box_y = <span class="built_in">sigmoid_f</span>(output_data[</span><br><span class="line">          max_anchor * (<span class="number">5</span> + classes) * stride + stride + i]);</span><br><span class="line">      <span class="type">float</span> box_w = <span class="built_in">expf</span>(output_data[</span><br><span class="line">          max_anchor * (<span class="number">5</span> + classes) * stride + <span class="number">2</span> * stride + i]);</span><br><span class="line">      <span class="type">float</span> box_h = <span class="built_in">expf</span>(output_data[</span><br><span class="line">          max_anchor * (<span class="number">5</span> + classes) * stride + <span class="number">3</span> * stride + i]);</span><br><span class="line">      box_w *= anchors[anchor_mask[tensor_idx][max_anchor]][<span class="number">0</span>];</span><br><span class="line">      box_h *= anchors[anchor_mask[tensor_idx][max_anchor]][<span class="number">1</span>];</span><br><span class="line">      std::cout &lt;&lt; <span class="string">&quot;box_x = &quot;</span> &lt;&lt; box_x</span><br><span class="line">        &lt;&lt; <span class="string">&quot; box_y = &quot;</span> &lt;&lt; box_y</span><br><span class="line">        &lt;&lt; <span class="string">&quot; box_w = &quot;</span> &lt;&lt; box_w</span><br><span class="line">        &lt;&lt; <span class="string">&quot; box_h = &quot;</span> &lt;&lt; box_h &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// regression</span></span><br><span class="line">      box_x += grid_x;</span><br><span class="line">      box_y += grid_y;</span><br><span class="line">      box_x /= (<span class="type">float</span>)width;</span><br><span class="line">      box_y /= (<span class="type">float</span>)height;</span><br><span class="line">      box_w /= (<span class="type">float</span>)resize_width;</span><br><span class="line">      box_h /= (<span class="type">float</span>)resize_height;</span><br><span class="line">      box_x -= box_w / <span class="number">2.f</span>;</span><br><span class="line">      box_y -= box_h / <span class="number">2.f</span>;</span><br><span class="line">      box_x *= (<span class="type">float</span>)image_origin_width;</span><br><span class="line">      box_y *= (<span class="type">float</span>)image_origin_height;</span><br><span class="line">      box_w *= (<span class="type">float</span>)image_origin_width;</span><br><span class="line">      box_h *= (<span class="type">float</span>)image_origin_height;</span><br><span class="line"></span><br><span class="line">      bbox.<span class="built_in">push_back</span>(&#123;(<span class="type">float</span>)batch_index, box_x, box_y, box_w, box_h,</span><br><span class="line">          max_confidence, (<span class="type">float</span>)max_index&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="上线性能及效果"><a href="#上线性能及效果" class="headerlink" title="上线性能及效果"></a>上线性能及效果</h2><p>整体跑下来我这边性能还是相当不错的，2080TI，10ms以内。后面有时间再更新一下其他卡的时间。</p>
<h2 id="接下来"><a href="#接下来" class="headerlink" title="接下来"></a>接下来</h2><p>代码这里主要参考的是这个repo：<a target="_blank" rel="noopener" href="https://github.com/AlexeyAB/darknet">https://github.com/AlexeyAB/darknet</a> 之所以没选用原版的darknet是因为这个repo代码结构更易读，同官方代码基本兼容，而且有比较不错的文档和说明<br>模型上线需要转tensorrt，选用了onnx作为中间模型，主要参考了: <a target="_blank" rel="noopener" href="https://gitlab.com/aminehy/YOLOv3-Darknet-ONNX-TensorRT">https://gitlab.com/aminehy/YOLOv3-Darknet-ONNX-TensorRT</a></p>
</div><div id="donate"><link rel="stylesheet" type="text/css" href="/css/donate.css?v=1.0.0"><script type="text/javascript" src="/js/donate.js?v=1.0.0" successtext="复制成功!"></script><a class="pos-f tr3" id="github" href="https://github.com/Kaiyuan/donate-page" target="_blank" title="Github"></a><div id="DonateText">Donate</div><ul class="list pos-f" id="donateBox"><li id="AliPay" qr="/images/zhifubao.jpg"></li><li id="WeChat" qr="/images/weixin.jpg"></li></ul><div class="pos-f left-100" id="QRBox"><div id="MainBox"></div></div></div><div class="post-copyright"><script type="text/javascript" src="/js/copyright.js?v=1.0.0" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copyright.css?v=1.0.0"><p><span>本文标题：</span>yolov3实战指南--训练自有数据集并完成TensorRT推理实践</p><p><span>文章作者：</span>throneclay</p><p><span>发布时间：</span>2020-03-05</p><p><span>最后更新：</span>2022-08-03</p><p><span>原始链接：</span><a href="/2020/03/05/yolo-learning2/">http://blog.throneclay.top/2020/03/05/yolo-learning2/</a><span class="copy-path"><i class="fa fa-clipboard" data-clipboard-text="http://blog.throneclay.top/2020/03/05/yolo-learning2/"></i></span></p><p><span>版权声明：</span>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</p></div><br><div class="tags"><a href="/tags/yolo"><i class="fa fa-tag">yolo</i></a></div><div class="post-nav"><a class="pre" href="/2020/03/10/libtorch_cpp/">libtorch c++ api上手指南</a><a class="next" href="/2020/02/19/yolo-learning/">yolov3论文详解--我们究竟在训练什么</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == 'true' ? true : false;
var verify = 'false' == 'true' ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'NqMIHIDAGzizQKypAqjrPjre-gzGzoHsz',
  appKey:'cHLz1Wk17aR4Mjr2LvimJRCm',
  placeholder:'评论一下',
  avatar:'wavatar',
  guest_info:guest_info,
  pageSize:'20'
})
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://blog.throneclay.top"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img src="/img/avatar.png"/></a><p>To be a better man.</p><a class="info-icon" href="https://github.com/throneclay" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/studyNotes/">学习笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/embeddedSystem/">嵌入式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/optimization/">性能优化</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machineLearning/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/deepLearning/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/compiler/">编译器</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/NEON/" style="font-size: 15px;">NEON</a> <a href="/tags/openmp/" style="font-size: 15px;">openmp</a> <a href="/tags/OpenCL/" style="font-size: 15px;">OpenCL</a> <a href="/tags/SIMD/" style="font-size: 15px;">SIMD</a> <a href="/tags/MIC/" style="font-size: 15px;">MIC</a> <a href="/tags/kernel%E5%BC%80%E5%8F%91/" style="font-size: 15px;">kernel开发</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/python%E5%A4%9A%E7%BA%BF%E7%A8%8B/" style="font-size: 15px;">python多线程</a> <a href="/tags/raspberryPi/" style="font-size: 15px;">raspberryPi</a> <a href="/tags/Deep-learning/" style="font-size: 15px;">Deep learning</a> <a href="/tags/%E9%AB%98%E9%A2%91%E4%BA%A4%E6%98%93/" style="font-size: 15px;">高频交易</a> <a href="/tags/MSP430/" style="font-size: 15px;">MSP430</a> <a href="/tags/caffe/" style="font-size: 15px;">caffe</a> <a href="/tags/mosquitto/" style="font-size: 15px;">mosquitto</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/theano/" style="font-size: 15px;">theano</a> <a href="/tags/llvm/" style="font-size: 15px;">llvm</a> <a href="/tags/LSTM/" style="font-size: 15px;">LSTM</a> <a href="/tags/SNAS/" style="font-size: 15px;">SNAS</a> <a href="/tags/pytorch/" style="font-size: 15px;">pytorch</a> <a href="/tags/yolo/" style="font-size: 15px;">yolo</a> <a href="/tags/archlinux/" style="font-size: 15px;">archlinux</a> <a href="/tags/shadowsocks/" style="font-size: 15px;">shadowsocks</a> <a href="/tags/nas/" style="font-size: 15px;">nas</a> <a href="/tags/CUDA/" style="font-size: 15px;">CUDA</a> <a href="/tags/gitlab/" style="font-size: 15px;">gitlab</a> <a href="/tags/ipython/" style="font-size: 15px;">ipython</a> <a href="/tags/vagrant/" style="font-size: 15px;">vagrant</a> <a href="/tags/Clion/" style="font-size: 15px;">Clion</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/ffmpeg/" style="font-size: 15px;">ffmpeg</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/08/08/confluence_synology/">使用docker部署支持备份，全docker环境的postgres+confluence环境</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/05/21/dsm7_gitlab/">在Synology DSM7.0上，找回我们熟悉的gitlab</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/23/llvm-note/">llvm编译的基本概念和流程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/06/py-multi-threads/">python多线程编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/10/libtorch_cpp/">libtorch c++ api上手指南</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/05/yolo-learning2/">yolov3实战指南--训练自有数据集并完成TensorRT推理实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/19/yolo-learning/">yolov3论文详解--我们究竟在训练什么</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/17/mqtt_protobuf/">mosquitto+protobuf实战</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/12/gitlab_runner/">你好小助手，帮我买瓶酱油--gitlab-runner搭建小记</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/23/ffmpeg_basic/">ffmpeg几种场景下的用法小记</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/throneclay" title="github" target="_blank">github</a><ul></ul><a href="http://zhangjikai.com/" title="zhangjikai" target="_blank">zhangjikai</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a target="_blank" rel="noopener" href="https://beian.miit.gov.cn/">京ICP备20008730号-1 <br></a><a href="/." rel="nofollow">流水的账.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>